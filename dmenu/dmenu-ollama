#!/usr/bin/env bash

# User-friendly interface for utilizing Ollama, for text-based tasks. 
#  * Checks necessary prerequisites.
#  * Prompts user to select a installed language model.
#  * Sends input text to Ollama.
#
# Ollama | Get up and running with large language models locally.
# https://github.com/jmorganca/ollama

set -e
[[ -v debug ]] && set -x

# Style
bold="\e[1m"
nc="\e[0m"

# Colors
red="\e[91m"
cyan="\e[36m"
yellow="\e[93m"

# Variables
OLLAMA_SERVER="127.0.0.1:11434"
PROGRAM=$(basename "$0")

msg() {
  echo -e "${PROGRAM}: ${cyan}$*${nc}"
}

error() {
	echo -e "${PROGRAM}: ${red}ERROR${nc}: $*"
	exit 1
}

kill_and_quit() {
	pkill ollama
	msg "$*"
	exit 0
}

is_available() {
	if ! command -v "$1" >/dev/null; then
		return 1
	fi
	return 0
}

get_model() {
	llm_list=$(ollama list | awk '{if (NR > 1) print $1}')
	llm_list+="\nkill server"
	model=$(echo -e "$llm_list" | dmenu -p 'Ollama' -l 10)
	[[ -z "$model" ]] && exit 1
	echo "$model"
}

get_clipboard() {
	clipboard=$(xclip -selection c -o 2>/dev/null)
	echo "$clipboard"
}

cleanup() {
  msg "Removing $1"
	rm "$1"
}

get_input() {
	local temp_file user_input
	temp_file=$(mktemp /tmp/temp_file_XXXXXX)
	st -n sptrans -c sptrans -g 130x30 -e bash -c "vim $temp_file"
	user_input=$(cat "$temp_file")
	cleanup "$temp_file"
	[[ -z "$user_input" ]] && exit 1
	echo "$user_input"
}

is_ollama_serve() {
	if curl -o /dev/null -sS --head "$OLLAMA_SERVER" 2>/dev/null; then
		return 0
	else
		return 1
	fi
}

run_ollama_serve() {
	ollama serve &
  exit 0
}

main() {
	echo -e "\n${bold}Ollama${nc} | Get up and running with large language models locally"

	model=$(get_model)

	if [ "$model" = "kill server" ]; then
		kill_and_quit "Ollama server killed."
	fi

	echo -e "\n${bold}Model${nc}: ${cyan}${model}${nc}\n"
	user_input=$(get_input)
	echo -e "${bold}User input${nc}:\n\n${yellow}${user_input}${nc}\n"
	ollama run "$model" "$user_input"
	read -p "Press ENTER to continue..." -r _
}

if is_available ollama && ! is_ollama_serve; then
	choose=$(echo -e "Start\nQuit" | dmenu -p 'Ollama: serve not found?>')
	[[ -z "$choose" ]] && exit 1
	if [[ "$choose" == "Start" ]]; then
		run_ollama_serve
	else
		exit 1
	fi
fi

main
